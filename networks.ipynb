{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "from tqdm import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(186)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_SENTENCE_LENGTH = 1000\n",
    "EMBED_SIZE = 300\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "PAD = '<pad>'\n",
    "UNK = '<unk>'\n",
    "\n",
    "label_to_id = {'contradiction' : 0, 'entailment' : 1, 'neutral' : 2}\n",
    "\n",
    "def load_fasttext():\n",
    "    fasttext_home = './'\n",
    "    words_to_load = 50000\n",
    "\n",
    "    loaded_embeddings = np.zeros((words_to_load + 2, EMBED_SIZE)) #+2 to account for pad and unk tokens\n",
    "    words = {}\n",
    "    idx2words = {}\n",
    "    with open(fasttext_home + 'wiki-news-300d-1M.vec') as f:\n",
    "        loaded_embeddings[PAD_IDX, :] = np.zeros((1, EMBED_SIZE))\n",
    "        loaded_embeddings[UNK_IDX, :] = np.zeros((1, EMBED_SIZE))\n",
    "        words[PAD] = PAD_IDX\n",
    "        words[UNK] = UNK_IDX\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= words_to_load: \n",
    "                break\n",
    "            s = line.split()\n",
    "            idx = i + 2 #+2 to account for PAD and UNK tokens\n",
    "            loaded_embeddings[idx, :] = np.asarray(s[1:])\n",
    "            words[s[0]] = idx \n",
    "            idx2words[idx] = s[0]\n",
    "    return loaded_embeddings, words, idx2words\n",
    "\n",
    "def load_snli_data():\n",
    "    snli_train = pd.read_csv('./snli_train.tsv', names=['sentence1', 'sentence2', 'label'], skiprows=1, sep='\\t|\\n', engine='python')\n",
    "    snli_val = pd.read_csv('./snli_val.tsv', names=['sentence1', 'sentence2', 'label'], skiprows=1, sep='\\t|\\n', engine='python')\n",
    "    return snli_train[['sentence1', 'sentence2']], [label_to_id[x] for x in snli_train['label']], snli_val[['sentence1', 'sentence2']], [label_to_id[x] for x in snli_val['label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_embeddings, words, idx2words = load_fasttext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_train_sentences, snli_train_labels, snli_val_sentences, snli_val_labels = load_snli_data()\n",
    "def map_sentence_to_idxs(sentence):\n",
    "    return [words[tkn] if tkn in words else UNK_IDX for tkn in sentence]\n",
    "snli_train_sentences_idxs = snli_train_sentences.applymap(lambda x: map_sentence_to_idxs(x))\n",
    "snli_val_sentences_idxs = snli_val_sentences.applymap(lambda x: map_sentence_to_idxs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIDataset(Dataset):    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: two sentence lists \n",
    "        @param target_list: list of targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.x1 = data_list['sentence1']\n",
    "        self.x2 = data_list['sentence2']\n",
    "        self.y = target_list\n",
    "        assert (len(self.x1) == len(self.x2) == len(self.y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "        \n",
    "    def __getitem__(self, key):        \n",
    "        sent1_idx = self.x1[key][:MAX_SENTENCE_LENGTH]\n",
    "        sent2_idx = self.x2[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.y[key]\n",
    "        return [sent1_idx, sent2_idx, len(sent1_idx), len(sent2_idx), label]\n",
    "\n",
    "def SNLI_collate_function(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    sentence1_list = []\n",
    "    sentence2_list = []\n",
    "    label_list = []\n",
    "    length_list_1 = []\n",
    "    length_list_2 = []\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        length_list_1.append(datum[2])\n",
    "        length_list_2.append(datum[3])\n",
    "        label_list.append(datum[4])\n",
    "        padded_vec_1 = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        sentence1_list.append(padded_vec_1)\n",
    "        padded_vec_2 = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        sentence2_list.append(padded_vec_2)\n",
    "    return [torch.from_numpy(np.array(sentence1_list)), torch.from_numpy(np.array(sentence2_list)), \n",
    "#             torch.cuda.LongTensor(length_list_1), torch.cuda.LongTensor(length_list_2), \n",
    "            torch.cuda.LongTensor(label_list)]\n",
    "#             torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_train_dataset = SNLIDataset(snli_train_sentences_idxs, snli_train_labels)\n",
    "snli_train_loader = torch.utils.data.DataLoader(dataset=snli_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_function,\n",
    "                                           shuffle=True)\n",
    "snli_val_dataset = SNLIDataset(snli_val_sentences_idxs, snli_val_labels)\n",
    "snli_val_loader = torch.utils.data.DataLoader(dataset=snli_val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_function,\n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers):\n",
    "        # BidirectionalGRU Accepts the following hyperparams:\n",
    "        # hidden_size: Hidden Size of layer in the GRU\n",
    "        # num_layers: number of layers in the GRU\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(loaded_embeddings), freeze=False)\n",
    "        self.gru = nn.GRU(EMBED_SIZE, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(self.num_layers*2, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "        lengths = (x.data != 0).sum(dim=1).cuda()\n",
    "        _, idx_sort = torch.sort(lengths, dim=0, descending=True) # sort in descending order of number of words\n",
    "        _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
    "        lengths = list(lengths[idx_sort])\n",
    "        idx_sort = torch.autograd.Variable(idx_sort).cuda()\n",
    "        idx_unsort = torch.autograd.Variable(idx_unsort).cuda()\n",
    "        \n",
    "        x = x.index_select(0, idx_sort)\n",
    "\n",
    "        embed = self.embedding(x)\n",
    "        #update embedding if token is unk\n",
    "        m = (x == 1).type(torch.cuda.FloatTensor)\n",
    "        m = m.unsqueeze(2).repeat(1, 1, EMBED_SIZE)\n",
    "        embed = m * embed + (1-m) * embed.clone().detach()\n",
    "        embed = torch.nn.utils.rnn.pack_padded_sequence(embed.cuda(), lengths, batch_first=True)\n",
    "        _, hidden = self.gru(embed.cuda(), self.hidden.cuda())\n",
    "        hidden = hidden[0, :, :] + hidden[1, :, :]\n",
    "        return hidden.index_select(0, idx_unsort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gru_model(loader, gru_model, fully_connected):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    gru_model.eval()\n",
    "    for sent1_batch, sent2_batch, labels_batch in loader:\n",
    "        hidden_1 = gru_model(sent1_batch.cuda())\n",
    "        hidden_2 = gru_model(sent2_batch.cuda())\n",
    "        encoded_output = torch.cat([hidden_1, hidden_2], dim=1).cuda()\n",
    "        outputs = []\n",
    "        for output in encoded_output:\n",
    "            outputs.append(fully_connected(output.cuda()))\n",
    "        outputs = torch.stack(outputs).cuda()\n",
    "        predicted = F.softmax(outputs)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        total += labels_batch.size(0)\n",
    "        correct += predicted.eq(labels_batch.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "def train_gru_model(hidden_size):\n",
    "    torch.cuda.empty_cache()\n",
    "    gru_model = BidirectionalGRU(hidden_size=hidden_size, num_layers=1)\n",
    "    gru_model = gru_model.cuda()\n",
    "\n",
    "    num_epochs = 10 # number epoch to train\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    learning_rate = 3e-4\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, gru_model.parameters()), lr=learning_rate)\n",
    "    fully_connected = nn.Sequential(nn.Linear(hidden_size*2, hidden_size), nn.ReLU(inplace=True), nn.Linear(hidden_size, 3)).cuda()\n",
    "\n",
    "    train_accs = {}\n",
    "    val_accs = {}\n",
    "    losses = {}\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (sent1, sent2, labels) in enumerate(snli_train_loader):\n",
    "            gru_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            hidden_1 = gru_model(sent1.cuda())\n",
    "            hidden_2 = gru_model(sent2.cuda())\n",
    "            encoded_output = torch.cat([hidden_1, hidden_2], dim=1).cuda()\n",
    "            outputs = []\n",
    "            for output in encoded_output:\n",
    "                outputs.append(fully_connected(output.cuda()))\n",
    "            outputs = torch.stack(outputs).cuda()\n",
    "            loss = criterion(outputs, labels.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i > 0 and i % 100 == 0):\n",
    "                val_acc = test_gru_model(snli_val_loader, gru_model, fully_connected)\n",
    "                train_acc = test_gru_model(snli_train_loader, gru_model, fully_connected)\n",
    "                train_accs[i + len(snli_train_loader)*epoch] = train_acc\n",
    "                val_accs[i + len(snli_train_loader)*epoch] = val_acc\n",
    "                losses[i + len(snli_train_loader)*epoch] = loss\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Training Acc: {}, Validation Acc: {}'.format(\n",
    "                           epoch+1, num_epochs, i+1, len(snli_train_loader), train_acc, val_acc))\n",
    "                \n",
    "    return gru_model, train_accs, val_accs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [101/782], Training Acc: 37.451, Validation Acc: 36.0\n",
      "Epoch: [1/10], Step: [201/782], Training Acc: 39.495, Validation Acc: 37.2\n",
      "Epoch: [1/10], Step: [301/782], Training Acc: 44.343, Validation Acc: 42.6\n",
      "Epoch: [1/10], Step: [401/782], Training Acc: 46.089, Validation Acc: 44.7\n",
      "Epoch: [1/10], Step: [501/782], Training Acc: 44.99, Validation Acc: 44.8\n",
      "Epoch: [1/10], Step: [601/782], Training Acc: 47.405, Validation Acc: 46.4\n",
      "Epoch: [1/10], Step: [701/782], Training Acc: 46.927, Validation Acc: 47.5\n",
      "Epoch: [2/10], Step: [101/782], Training Acc: 47.546, Validation Acc: 47.9\n",
      "Epoch: [2/10], Step: [201/782], Training Acc: 48.144, Validation Acc: 47.9\n",
      "Epoch: [2/10], Step: [301/782], Training Acc: 48.591, Validation Acc: 47.0\n",
      "Epoch: [2/10], Step: [401/782], Training Acc: 48.691, Validation Acc: 47.5\n",
      "Epoch: [2/10], Step: [501/782], Training Acc: 50.003, Validation Acc: 49.8\n",
      "Epoch: [2/10], Step: [601/782], Training Acc: 50.277, Validation Acc: 50.6\n",
      "Epoch: [2/10], Step: [701/782], Training Acc: 50.549, Validation Acc: 51.4\n",
      "Epoch: [3/10], Step: [101/782], Training Acc: 51.223, Validation Acc: 50.6\n",
      "Epoch: [3/10], Step: [201/782], Training Acc: 51.061, Validation Acc: 50.1\n",
      "Epoch: [3/10], Step: [301/782], Training Acc: 51.735, Validation Acc: 51.5\n",
      "Epoch: [3/10], Step: [401/782], Training Acc: 52.109, Validation Acc: 51.4\n",
      "Epoch: [3/10], Step: [501/782], Training Acc: 52.357, Validation Acc: 51.3\n",
      "Epoch: [3/10], Step: [601/782], Training Acc: 52.338, Validation Acc: 51.5\n",
      "Epoch: [3/10], Step: [701/782], Training Acc: 52.687, Validation Acc: 51.2\n",
      "Epoch: [4/10], Step: [101/782], Training Acc: 53.196, Validation Acc: 52.4\n",
      "Epoch: [4/10], Step: [201/782], Training Acc: 53.667, Validation Acc: 54.3\n",
      "Epoch: [4/10], Step: [301/782], Training Acc: 53.801, Validation Acc: 52.7\n",
      "Epoch: [4/10], Step: [401/782], Training Acc: 54.249, Validation Acc: 54.2\n",
      "Epoch: [4/10], Step: [501/782], Training Acc: 53.477, Validation Acc: 54.4\n",
      "Epoch: [4/10], Step: [601/782], Training Acc: 54.519, Validation Acc: 55.0\n",
      "Epoch: [4/10], Step: [701/782], Training Acc: 54.794, Validation Acc: 54.7\n",
      "Epoch: [5/10], Step: [101/782], Training Acc: 55.072, Validation Acc: 53.9\n",
      "Epoch: [5/10], Step: [201/782], Training Acc: 54.417, Validation Acc: 54.7\n",
      "Epoch: [5/10], Step: [301/782], Training Acc: 55.569, Validation Acc: 55.1\n",
      "Epoch: [5/10], Step: [401/782], Training Acc: 55.816, Validation Acc: 55.8\n",
      "Epoch: [5/10], Step: [501/782], Training Acc: 56.001, Validation Acc: 56.8\n",
      "Epoch: [5/10], Step: [601/782], Training Acc: 56.51, Validation Acc: 58.2\n",
      "Epoch: [5/10], Step: [701/782], Training Acc: 56.119, Validation Acc: 57.0\n",
      "Epoch: [6/10], Step: [101/782], Training Acc: 56.75, Validation Acc: 57.6\n",
      "Epoch: [6/10], Step: [201/782], Training Acc: 56.233, Validation Acc: 58.2\n",
      "Epoch: [6/10], Step: [301/782], Training Acc: 57.095, Validation Acc: 58.1\n",
      "Epoch: [6/10], Step: [401/782], Training Acc: 57.33, Validation Acc: 57.8\n",
      "Epoch: [6/10], Step: [501/782], Training Acc: 57.594, Validation Acc: 56.9\n",
      "Epoch: [6/10], Step: [601/782], Training Acc: 57.563, Validation Acc: 57.1\n",
      "Epoch: [6/10], Step: [701/782], Training Acc: 57.454, Validation Acc: 56.4\n",
      "Epoch: [7/10], Step: [101/782], Training Acc: 58.084, Validation Acc: 57.9\n",
      "Epoch: [7/10], Step: [201/782], Training Acc: 58.159, Validation Acc: 58.4\n",
      "Epoch: [7/10], Step: [301/782], Training Acc: 57.961, Validation Acc: 59.2\n",
      "Epoch: [7/10], Step: [401/782], Training Acc: 58.51, Validation Acc: 58.3\n",
      "Epoch: [7/10], Step: [501/782], Training Acc: 58.001, Validation Acc: 59.0\n",
      "Epoch: [7/10], Step: [601/782], Training Acc: 59.001, Validation Acc: 59.8\n",
      "Epoch: [7/10], Step: [701/782], Training Acc: 59.045, Validation Acc: 59.3\n",
      "Epoch: [8/10], Step: [101/782], Training Acc: 58.972, Validation Acc: 58.5\n",
      "Epoch: [8/10], Step: [201/782], Training Acc: 59.459, Validation Acc: 59.2\n",
      "Epoch: [8/10], Step: [301/782], Training Acc: 59.399, Validation Acc: 58.9\n",
      "Epoch: [8/10], Step: [401/782], Training Acc: 59.472, Validation Acc: 58.9\n",
      "Epoch: [8/10], Step: [501/782], Training Acc: 59.483, Validation Acc: 58.3\n",
      "Epoch: [8/10], Step: [601/782], Training Acc: 59.926, Validation Acc: 59.3\n",
      "Epoch: [8/10], Step: [701/782], Training Acc: 60.124, Validation Acc: 60.3\n",
      "Epoch: [9/10], Step: [101/782], Training Acc: 59.678, Validation Acc: 61.4\n",
      "Epoch: [9/10], Step: [201/782], Training Acc: 60.207, Validation Acc: 59.9\n",
      "Epoch: [9/10], Step: [301/782], Training Acc: 60.375, Validation Acc: 59.7\n",
      "Epoch: [9/10], Step: [401/782], Training Acc: 60.563, Validation Acc: 59.0\n",
      "Epoch: [9/10], Step: [501/782], Training Acc: 60.494, Validation Acc: 60.2\n",
      "Epoch: [9/10], Step: [601/782], Training Acc: 60.694, Validation Acc: 59.8\n",
      "Epoch: [9/10], Step: [701/782], Training Acc: 60.123, Validation Acc: 58.3\n",
      "Epoch: [10/10], Step: [101/782], Training Acc: 60.831, Validation Acc: 60.7\n",
      "Epoch: [10/10], Step: [201/782], Training Acc: 61.066, Validation Acc: 59.5\n",
      "Epoch: [10/10], Step: [301/782], Training Acc: 60.806, Validation Acc: 60.5\n",
      "Epoch: [10/10], Step: [401/782], Training Acc: 61.293, Validation Acc: 60.4\n",
      "Epoch: [10/10], Step: [501/782], Training Acc: 61.352, Validation Acc: 60.5\n",
      "Epoch: [10/10], Step: [601/782], Training Acc: 61.382, Validation Acc: 60.3\n",
      "Epoch: [10/10], Step: [701/782], Training Acc: 61.452, Validation Acc: 59.7\n"
     ]
    }
   ],
   "source": [
    "gru_model, gru_train_accs, gru_val_accs, gru_losses = train_gru_model(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(loaded_embeddings), freeze=False)\n",
    "    \n",
    "        self.conv1 = nn.Conv1d(EMBED_SIZE, hidden_size, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "\n",
    "        embed = self.embedding(x)\n",
    "        hidden = self.conv1(embed.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(batch_size, seq_len, hidden.size(-1))\n",
    "\n",
    "        hidden = self.conv2(hidden.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(batch_size, seq_len, hidden.size(-1))\n",
    "\n",
    "        hidden = torch.sum(hidden, dim=1)\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn_model(loader, cnn_model, fully_connected):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    cnn_model.eval()\n",
    "    for sent1_batch, sent2_batch, labels_batch in loader:\n",
    "        hidden_1 = cnn_model(sent1_batch.cuda())\n",
    "        hidden_2 = cnn_model(sent2_batch.cuda())\n",
    "        encoded_output = torch.cat([hidden_1, hidden_2], dim=1).cuda()\n",
    "        outputs = []\n",
    "        for output in encoded_output:\n",
    "            outputs.append(fully_connected(output.cuda()))\n",
    "        outputs = torch.stack(outputs).cuda()\n",
    "        predicted = F.softmax(outputs)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        total += labels_batch.size(0)\n",
    "        correct += predicted.eq(labels_batch.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "def train_cnn_model(hidden_size):\n",
    "    torch.cuda.empty_cache()\n",
    "    cnn_model = CNN(hidden_size=hidden_size, num_layers=2)\n",
    "    cnn_model = cnn_model.cuda()\n",
    "\n",
    "    num_epochs = 10 # number epoch to train\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    learning_rate = 3e-4\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, cnn_model.parameters()), lr=learning_rate)\n",
    "    fully_connected = nn.Sequential(nn.Linear(hidden_size*2, hidden_size), nn.ReLU(inplace=True), nn.Linear(hidden_size, 3)).cuda()\n",
    "\n",
    "    train_accs = {}\n",
    "    val_accs = {}\n",
    "    losses = {}\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (sent1, sent2, labels) in enumerate(snli_train_loader):\n",
    "            cnn_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            hidden_1 = cnn_model(sent1.cuda())\n",
    "            hidden_2 = cnn_model(sent2.cuda())\n",
    "            encoded_output = torch.cat([hidden_1, hidden_2], dim=1).cuda()\n",
    "            outputs = []\n",
    "            for output in encoded_output:\n",
    "                outputs.append(fully_connected(output.cuda()))\n",
    "            outputs = torch.stack(outputs).cuda()\n",
    "            loss = criterion(outputs, labels.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i > 0 and i % 100 == 0):\n",
    "                val_acc = test_cnn_model(snli_val_loader, cnn_model, fully_connected)\n",
    "                train_acc = test_cnn_model(snli_train_loader, cnn_model, fully_connected)\n",
    "                train_accs[i + len(snli_train_loader)*epoch] = train_acc\n",
    "                val_accs[i + len(snli_train_loader)*epoch] = val_acc\n",
    "                losses[i + len(snli_train_loader)*epoch] = loss\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Training Acc: {}, Validation Acc: {}'.format(\n",
    "                           epoch+1, num_epochs, i+1, len(snli_train_loader), train_acc, val_acc))\n",
    "                \n",
    "    return cnn_model, train_accs, val_accs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model, cnn_train_accs, cnn_val_accs, cnn_losses = train_cnn_model(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
